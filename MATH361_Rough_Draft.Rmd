---
title: "Predicting Bike Share Ridership based on Weather Data in Seattle"
author: "Joey Rodriguez and Daniel Bhatti"
date: "2024-11-22"
output:
  pdf_document: default
  html_document: default
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#imports 
library(readr)
library(dplyr)
library(car)
library(tinytex)
library(ggplot2)
library(patchwork)
library(zoo)
library(knitr)
```

# Introduction
Cycle share has launched in many U.S. cities since its introduction in Washington, D.C. in 2010 (1). One iteration of cycle share was Pronto! based in Seattle, Washington. From 2014 to 2017, 500 Pronto! bikes operated across 54 stations in Seattle’s downtown. The City of Seattle, in partnership with Socratica, collected system data during the operating window and provided it to the public via its open data platform. Pronto fell short of the success realized by other bike schemes in the U.S. like Capitol Bikes, Philly’s Indego, and NYC’s CitiBike. Researchers have used system data to conduct a post-mortem on Pronto! as dockless bike share schemes filled the void (2). In this paper, we will investigate the relationship between weather in the service area and daily ridership. In particular, we want to predict daily ridership based on the weather data.

The data were downloaded from Kaggle (3). The file \texttt{trip.csv} contains data on each trip from 13 October 2014 to 31 March 2017, or 901 days. Each case in this dataset is a trip, and there were 275,091 trips over the 901 days. The relevant variables from the original 12 in this dataset are the response variables \texttt{start\_time} and \texttt{trip\_duration}. In the file \texttt{weather.csv.xls}, a single case corresponds to a single day. This file contains the weather data for each day from 13 October 2014 to 31 August 2016, or 689 days. That is, the dates covered by the weather data are a proper subset of the dates covered by the trip data. After merging these data and creating some of our own variables, we move on to exploratory data analysis for the response variables and predictors. This exploration informs our choice for our final model.

[INSERT PARAGRAPH SUMMARIZING CONCLUSIONS FROM THE RESEARCH]


```{r, echo=FALSE, fig.cap = "PRETTY FIGURE", out.width = "50%"}
knitr::include_graphics("pronto.png")
```

# Exploratory Data Analysis

## Data Cleaning
The \texttt{trip} data frame contains 175,091 cases (or rides) and 12 variables describing each ride. The weather data frame contains 689 cases (or days) and 21 variables describing the weather that day. Ultimately, our goal is to join these two data frames. We began by aggregating trip data for each day we have data for. 

From the \texttt{trip} data frame, we selected only two variables: \texttt{start\_time} and \texttt{tripduration}. We stripped the date from the \texttt{start\_time} (encoded in the format \texttt{\%m/\%d/\%Y \%H:\%M}), collected the unique dates, and mapped unique dates to the natural numbers. The mapping was represented by a new variable called \texttt{day\_number}. Now, each trip has a duration \texttt{tripduration}, a trip \texttt{count} (1), and a \texttt{day\_number} (ranging from 1 to 689). From the \texttt{trip} data frame, we created a new data frame called \texttt{ridership} that aggregates trips by day. At the end of this, \texttt{ridership} has 901 rows (days) and 3 columns (variables): \texttt{count}, \texttt{tripduration}, and \texttt{day\_number}.

From the \texttt{weather} data frame, we used the mapping created for the \texttt{trip} data set to map unique dates to the natural numbers. We also created a new variable, \texttt{temp\_range}, by computing the difference between \texttt{Max\_Temperature\_F} and \texttt{Min\_TemperatureF} for each day. Because the \texttt{trip} data covers 212 days after the last observation in the \texttt{weather} data, we want to keep only the observations in \texttt{trip} that match the observations in the smaller data frame, \texttt{weather}. We created our final data frame, \texttt{df}, by left joining weather and ridership by \texttt{day\_number}. The final data frame contains 689 rows (days) and 25 columns (variables). The variable names are listed in a table below with brief descriptions.

```{r rtable, echo = FALSE}
# Create a data frame with variable names and descriptions
variable_descriptions <- data.frame(
  Variable = c(
    "Max_Temperature_F", "Mean_Temperature_F", "Min_TemperatureF",
    "Max_Dew_Point_F", "MeanDew_Point_F", "Min_Dewpoint_F",
    "Max_Humidity", "Mean_Humidity", "Min_Humidity",
    "Max_Sea_Level_Pressure_In", "Mean_Sea_Level_Pressure_In", "Min_Sea_Level_Pressure_In",
    "Max_Visibility_Miles", "Mean_Visibility_Miles", "Min_Visibility_Miles",
    "Max_Wind_Speed_MPH", "Mean_Wind_Speed_MPH", "Max_Gust_Speed_MPH",
    "Precipitation_In", "Events", "temp_range", "date", "day_number",
    "total_trips", "total_durations", "average_durations"
  ),
  Description = c(
    "Maximum temperature in Fahrenheit recorded that day",
    "Mean temperature in Fahrenheit recorded that day",
    "Minimum temperature in Fahrenheit recorded that day",
    "Maximum dew point in Fahrenheit recorded that day",
    "Mean dew point in Fahrenheit recorded that day",
    "Minimum dew point in Fahrenheit recorded that day",
    "Maximum humidity percentage recorded that day",
    "Mean humidity percentage recorded that day",
    "Minimum humidity percentage recorded that day",
    "Maximum sea-level pressure in inches recorded that day",
    "Mean sea-level pressure in inches recorded that day",
    "Minimum sea-level pressure in inches recorded that day",
    "Maximum visibility in miles recorded that day",
    "Mean visibility in miles recorded that day",
    "Minimum visibility in miles recorded that day",
    "Maximum wind speed in miles per hour recorded that day",
    "Mean wind speed in miles per hour recorded that day",
    "Maximum gust speed in miles per hour recorded that day",
    "Precipitation in inches recorded that day",
    "Weather events (e.g., Rain, Snow) that occurred that day",
    "Temperature range (Max_Temperature_F - Min_TemperatureF)",
    "Date of the observation",
    "Days since 13 October 2014",
    "Total trips recorded that day",
    "Total duration of all trips recorded that day in seconds",
    "Average ride duration for that day"
  )
)

# Render the table using kable
knitr::kable(variable_descriptions, col.names = c("Variable", "Description"), caption = "Variable Descriptions (689 rows, 25 columns)")

```

## Selecting the Response Variable
The three candidates for a good response variable were created from the ``trip.csv`` data set, described in the ``ridership`` data frame, and merged into our final data frame: ``total_trips``, ``trip_durations``, and ``avg_durations``. We briefly discuss the merits of each response variable before a quantitative judgement:
\begin{itemize}
\item \texttt{total\_trips} is the most intuitive measure for bike ridership on a given day. It directly answers the question ``How many trips were there?'' for a given day. It gives us a picture of how willing people in the service area were to hop on a bike.
\item \texttt{total\_durations} gives a more complete picture for the ridership on a given day. Once a rider hopped on a bike, how long did they ride before docking it? This gives us a picture of how willing riders in the service area were to stay on their bikes.
\item \texttt{avg\_durations} controls for the interaction between bike ridership and ridership durations. By dividing total ridership over total durations, we understand the willingness of those in the service area to both picking up a bike and keep riding on that bike.
\end{itemize}

Below is daily bike ridership in Seattle, visualized with both the total rides taken each day and the total of the durations of the rides taken each day. This figure suggests that outliers in total riders tend to coincide with outliers in ride durations. FOR EXAMPLE... IDENTIFY THE POINT. PROVIDE SOME MORE SUMMARY STATS This coincidence has a flattening effect when we find the average ride durations per day. In fact, the minimum average ride duration record is IDENTIY THIS POINT. PROVIDE SOME MORE SUMMARY STATS. We choose to skip a visualization of the average each day to visualizing the normality of the data.



```{r mapping, include=FALSE}
trip = read_csv('pronto-cycle-share-trip-data.csv')
# map unique dates to integers starting at 1

trip$date <- as.Date(trip$starttime, format = "%m/%d/%Y %H:%M") # strips the date from its current format
unique_dates <- sort(unique(trip$date)) # this collects unique dates
date_to_number <- setNames(seq_along(unique_dates), as.character(unique_dates)) # this maps unique date to the integers, starting at 1
trip$day_number = date_to_number[as.character(trip$date)] # this adds the integer mapping as a column, day_number
trip$count = 1 # this adds a one to each obs; useful for add
trip = select(trip, count, tripduration, day_number)

# construct new df, ridership, that aggregates trips by day
ridership = trip %>% group_by(day_number) %>%
  summarise(total_trips = sum(count),
            total_durations = sum(tripduration),
            .groups = 'drop'); dim(ridership)
```

```{r clean_data, include = FALSE}
weather = read_csv('weather.csv.xls')

weather$temp_range = weather$Max_Temperature_F - weather$Min_TemperatureF # calculates temperature range for each day

weather$date <- as.Date(weather$Date, format = "%m/%d/%Y") # strips the date from its current format

# maps unique date to the integers, like the chunk above
date_to_number <- setNames(seq_along(unique_dates), as.character(unique_dates))
weather$day_number = date_to_number[as.character(weather$date)]

weather = weather[,-1] # remove the old date

# this will be our data frame going forward
df = left_join(weather,ridership, by='day_number'); dim(df)

df$avg_durations = df$total_durations / df$total_trips
```

```{r plot_y, echo = FALSE}

par(mar = c(4, 4, 4, 4) + 0.1)  # Increase the right margin (4th value)

# Set up the plot
plot(df$day_number, df$total_trips, 
     xlab = "Days since 13 October 2014", 
     ylab = "Total Bike Ridership", 
     col = "black", 
     bg = "blue",
     pch = 21, 
     ylim = c(0, max(df$total_trips)))  # Primary Y-axis

# Overlay the second dataset
par(new = TRUE)  # Add a new plot without clearing the previous one
plot(df$day_number, df$total_durations, 
     xlab = "", 
     ylab = "", 
     col = "black", 
     bg = "red",
     pch = 24, 
     axes = FALSE,  # Suppress axes for this plot
     ylim = c(0, max(df$total_durations)))  # Secondary Y-axis scale

# Add the secondary Y-axis
axis(4)  # Right Y-axis in red
mtext("Total Durations (secs)", side = 4, line = 3)  # Label for right Y-axis

# Add a title for the entire plot
title(main = "Daily Bike Share Ridership in Seattle", line = 1, cex.main = 1.25)

# Add a legend to differentiate datasets
legend("topright", legend = c(expression(Sigma ~ "Riders"), expression(Sigma ~ "Durations (secs)")), 
       col = c("black", "black"), 
       pt.bg = c("blue", "red"),
       pch = c(21, 24), 
       bty = "n")  # No box around the legend

```


```{r plot_hist, echo = FALSE}
par(mfrow = c(3, 2),       # Create a 3x2 grid
    mar = c(2, 2, 2, 1),   # Reduce margins around individual plots (bottom, left, top, right)
    oma = c(4, 4, 2, 2))   # Set outer margins for the entire figure

hist(df$total_trips, xlab='', main='Total Trips'); hist(log(df$total_trips), xlab='', main='log(Total Trips)')
hist(df$total_durations, xlab='', main='Total Durations'); hist(log(df$total_durations), xlab='', main='log(Total Durations)')
hist(df$avg_durations, xlab='', main='Average Durations'); hist(log(df$avg_durations), xlab='', main='log(Average Durations)')
```



## Outliers


# Methods/ Analysis
```{r plot predictors, echo=FALSE}
par(mfrow=c(2,2), mai = c(1,0.1,0.1,0.1))
plot(df$Precipitation_In,df$total_trips, xlab = "Precipitation (in)"); abline(reg = lm(df$total_trips ~ df$Precipitation_In), col = 'red')

plot(df$Mean_Temperature_F,df$total_trips, xlab = "Mean Temperature (F)"); abline(reg = lm(df$total_trips ~ df$Mean_Temperature_F), col = 'red')

plot(df$Mean_Humidity,df$total_trips, xlab = "Mean Humidity (%)"); abline(reg = lm(df$total_trips ~ df$Mean_Humidity), col = 'red')

plot(df$Mean_Wind_Speed_MPH, df$total_trips, xlab = "Mean Wind Speed (MPH)"); abline(reg = lm(df$total_trips ~ df$Mean_Wind_Speed_MPH), col = 'red')
```

```{r plot diag plots, echo=FALSE}
out = lm(total_trips ~ Mean_Temperature_F, data = df)
#par(mfrow=c(2,2))
#plot(out)
#summary(out)
#Adjusted R^2 is 0.5612

outHum = lm(total_trips ~ Mean_Humidity, data = df)
par(mfrow=c(2,2))
plot(outHum)
summary(outHum)
#Diagnostic plots look incredible. Adj R^2 = 0.4611

outRain = lm(total_trips ~ Precipitation_In, data = df)
#par(mfrow=c(2,2))
#plot(outRain)
#summary(outRain)

outWind = lm(total_trips ~ Mean_Wind_Speed_MPH, data =df)
#par(mfrow=c(2,2))
#plot(outWind)
#summary(outWind)
#Plots bad, R^2 <0.2
```

```{r modelling, include = FALSE}
rainResiduals <- resid(outRain)
windResiduals <- resid(outWind)

variance_rain = lm(abs(windResiduals) ~ Mean_Wind_Speed_MPH, data = df)

rainpredictedvar = predict(variance_rain)

rainweights = 1/(rainpredictedvar^2)

RainWLS <- lm(total_trips ~ Precipitation_In, data = df, weights = rainweights)

#RainWLS did not produce meaningful improvements.

outDew = lm(total_trips ~ MeanDew_Point_F, data = df)

#Great plots R^2 is only 0.2

outWind = lm(total_trips ~ Mean_Wind_Speed_MPH, data = df)

#Good plots R^2 is a paltry 0.07

windweights <- 1/lm(abs(outWind$residuals)~outWind$fitted.values)$fitted.values^2

WindWLS <- lm(total_trips ~ Mean_Wind_Speed_MPH, data = df, weights = windweights)

#Using WLS on windspeed significantly improves it. The R^2 is 0.7

outRange = lm(total_trips ~ temp_range, data = df)

#Plots have 1 extremely influential point, the R^2 is 0.315
#If we are to use mean temp I think we can ignore this variable (as a basic regressor)

outVisible = lm(total_trips ~ Mean_Visibility_Miles, data = df)

#Plots are mid, R^2 is 0.1313

visresid =  resid(outVisible)

variance_vis = lm(abs(visresid)~Mean_Visibility_Miles, data=df)

vispredictvar = predict(variance_vis)

visweights = 1/(vispredictvar^2)

VisWLS <- lm(total_trips ~ Mean_Visibility_Miles, data = df, weights = visweights)

#Very unimpressive.

outSea = lm(total_trips ~ Mean_Sea_Level_Pressure_In, data = df)

#Criteria for being in full model is that it had a *** significance by itself

fullmodel = lm(total_trips ~ Mean_Temperature_F + Mean_Humidity+MeanDew_Point_F+Precipitation_In+Mean_Wind_Speed_MPH+Mean_Visibility_Miles, data = df)

#Very interestingly Mean temp is not significant. Additionally visibility is far from significant

#Diagnostic plots look very good. R^2 is 0.71

partialmodel = lm(total_trips ~ Mean_Temperature_F + Mean_Humidity+MeanDew_Point_F+Precipitation_In+Mean_Wind_Speed_MPH, data = df)

partialmodel2 = lm(total_trips ~ Mean_Humidity+MeanDew_Point_F+Precipitation_In+Mean_Wind_Speed_MPH, data = df)

#Good diagnostics, R^2 is 0.71, all regressors are significant.

#I think that this is the best model.

testmodel = lm(total_trips ~ Mean_Temperature_F + MeanDew_Point_F, data=df)

#R^2 0.63, good diagnostics.

testmodel2 = lm(total_trips ~ Mean_Temperature_F + Mean_Humidity, data=df)

#R^2 0.6487, good diagnostics

testmodel3 = lm(total_trips ~ Mean_Temperature_F + Mean_Humidity+MeanDew_Point_F, data=df)

#Suddenly temperature is not significant


#powerTransform(cbind(df$total_trips,df$Mean_Temperature_F,df$#Mean_Humidity,df$MeanDew_Point_F,df$Precipitation_In,df$Mean_#Wind_Speed_MPH,df$Mean_Visibility_Miles))

#This fails as powerTransform needs arguments to be strictly positive and the min
#of Precipitation and Wind speed are 0

powerTransform(cbind(df$total_trips,df$Mean_Temperature_F,df$Mean_Humidity,df$MeanDew_Point_F,df$Mean_Visibility_Miles))

#trips: 0.761, Temperature: 0.760, Humidity: 0.67, Dew point 1.1, Visibility 10

#Therefore trips 3/4, temperate 3/4, humidity 2/3, Dew point no change visibility, visibility^2

df$total_trips_trans <- df$total_trips^(3/4)
df$Mean_Temperature_F_trans <- df$Mean_Temperature_F^(3/4)
df$Mean_Humidity_trans <- df$Mean_Humidity^(2/3)
df$Mean_Visibility_Miles_trans <- df$Mean_Visibility_Miles^2

df$total_trips_trans <- df$total_trips^(3/4)
df$Mean_Temperature_F_trans <- df$Mean_Temperature_F^(3/4)
df$Mean_Humidity_trans <- df$Mean_Humidity^(2/3)
df$Mean_Visibility_Miles_trans <- df$Mean_Visibility_Miles^10

transform_out <- lm(total_trips_trans ~ Mean_Temperature_F_trans + Mean_Humidity_trans + MeanDew_Point_F + Mean_Visibility_Miles_trans, data = df)

#The transformed model is not very impressive. Good diagnostics, R^2 of 0.6484

partialmodel3 = lm(total_trips ~ Mean_Humidity+MeanDew_Point_F+Precipitation_In+Mean_Wind_Speed_MPH+Max_Temperature_F, data = df)

#Best model

partialmodel4 = lm(total_trips ~ Mean_Humidity+MeanDew_Point_F+Precipitation_In+Mean_Wind_Speed_MPH+Max_Temperature_F+temp_range, data = df)

fullmodel2 = lm(total_trips ~ Mean_Temperature_F + Mean_Humidity+MeanDew_Point_F+Precipitation_In+Mean_Wind_Speed_MPH+Mean_Visibility_Miles+Mean_Sea_Level_Pressure_In, data = df)

anova(partialmodel,fullmodel2)

```

# Conclusion/Discussion



```{r, echo=FALSE, include=FALSE}
cor(df$total_durations,df$total_trips)
#Total trips and total durations are only 82.2% correlated

cor(df$total_durations, df$Mean_Temperature_F, use = "complete.obs")

cor(df$total_durations, df$MeanDew_Point_F)


```




## Model Selection

Our model and how we derived it:

The equation for our final regression model is:

  \texttt{total\_trips} = 277.1643 – 4.95(\texttt{Mean\_Humidity}) + 5.90(\texttt{MeanDew\_Point}) – 118.151(\texttt{Precipitation\_In}) – 7.91(\texttt{Mean\_Wind\_Speed}) + 2.94(\texttt{Max\_Temperature})

Each regressor is significant to at least the 0.01 level, and the diagnostic plots are satisfactory. The residual plot moving-average looks flat. The normal quantile plot has few departures from the line. The scale location plot is relatively flat, indicating constant variance across fitted values. 

In order to obtain this model, we first did some exploratory data analysis, plotting total trips against certain variables and obtaining their correlation. We then attemped several basic (single regressor) linear models of total_trips vs some of our variables. The variables that we considered were: mean temperature, mean humidity, mean dew point, precipitation in inches, mean wind speed, mean miles of visibility, mean sea level pressure,  temperature range, and max temperature. These were the original variables we considered on account of the fact that they seemed to have some relationship with total trips based on plots and correlation, and made sense to us as predictors of ridership from an intuitive perspective. After trying several single variable models, we found that few of them had very high R^2, with a  notable exception that a weighted least squares model of wind speed high worked very well. We then decided to make a “full” model with all of the variables above, except only using mean temperature instead of temperature range and max temperature as 1. mean and max were extremely highly correlated (>97%) and 2. we thought two temperature variables would be redundant. The output of the full model showed that Mean temperature, mean visibility miles, and mean sea level pressure did not have coefficients that were significantly different from zero. We made a model dropping these parameters and then did an anova (partial f) between the two models to see if we could justifiably drop them and it showed that we could. At this point all of the predictors were significant and the adjusted R^2 was 0.7095. However, we got the idea to try adding temperature range or max temperature to this model. Including temperature range did not improve the R^2, and it was not significant in the model, however, including max temperature did improve the adjusted R^2 and the regressor was also significant. We decided that this would be our final model. Each regressor is significant at at least the 0.01 level, and the diagnostic plots look good. The adjusted R^2 is 0.712. 
We also tried to use powerTransformations, but it only worked for some of the variables as others did not have strictly positive values. For the variables that did successfully power transform, the adjusted R^2 of the subsequent model was not greatly improved and few of the regressors were significant. 
Our final model has some nice properties, in that the diagnostic plots show that it satisfies the assumptions for linear regression well, it is perfectly basic in terms of transformations, and partly on account of that, it is not too difficult to interpret. 
In terms of interpretation, our model predicts that holding all else equal, every 1% increase in average humidity will lead the total number of bike trips to decrease by 4.95. It predicts that holding all else equal, for every 1 degree increase in the average dew point (Fahrenheit for this and all future mentions of degrees) Seattle will see a drop in bike trips of 5.90.  Our model predicts that all else equal, for every 1 extra inch of precipitation, total bike rides will drop by 118. It also predicts that holding all else equal, a 1 mile per hour increase in the average wind speed will decrease total bike trips by 7.91. Lastly our model predicts that holding all else equal, a 1 degree increase in the maximum temperature will increase the number of bike trips by 2.94. 

```{r final model, echo = FALSE}
partialmodel3 = lm(total_trips ~ Mean_Humidity+MeanDew_Point_F+Precipitation_In+Mean_Wind_Speed_MPH+Max_Temperature_F, data = df)

#regression summary of the final model
summary(partialmodel3)

# diagnostic plots
par(mfrow=c(2,2))
plot(partialmodel3)

# pairs plot
pairs(~Mean_Humidity + MeanDew_Point_F + Precipitation_In + Mean_Wind_Speed_MPH + Max_Temperature_F, data = df)
```

## Cross Validation

# Conclusion
Our work here suggests a path forward for bike share systems looking to bolster their operations and planning with weather data. However, Seattle is a city with temperate weather/climate. These results are not readily generalizable to all cities because when its too hot, people will also not ride bike!

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. 

